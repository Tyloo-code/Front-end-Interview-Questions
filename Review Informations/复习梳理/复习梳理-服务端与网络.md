---
title: '【面】前端知识点梳理（服务端与网络）'
date: 2021-03-11 13:56:39
tags: [Interview]
published: true
hideInList: false
feature: 
isTop: false
---
# 1. 常见状态码
`1XX 信息`   
消息:|描述:
:--:|:--:|
100 Continue|服务器仅接收到部分请求，但是一旦服务器并没有拒绝该请求，客户端应该继续发送其余的请求。
101 Switching Protocols|服务器转换协议：服务器将遵从客户的请求转换到另外一种协议。

`2XX 成功`   
消息:|描述:
:--:|:--:|
200 OK|请求成功（其后是对GET和POST请求的应答文档。）
201 Created|请求被创建完成，同时新的资源被创建。
202 Accepted|供处理的请求已被接受，但是处理未完成。
203 Non-authoritative Information|文档已经正常地返回，但一些应答头可能不正确，因为使用的是文档的拷贝。
204 No Content|没有新文档。浏览器应该继续显示原来的文档。如果用户定期地刷新页面，而Servlet可以确定用户文档足够新，这个状态代码是很有用的。

`3XX 重定向`
消息:|描述:
:--:|:--:|
300 Multiple Choices|多重选择。链接列表。用户可以选择某链接到达目的地。最多允许五个地址。
301 Moved Permanently|所请求的页面已经转移至新的url。
302 Found|所请求的页面已经临时转移至新的url。
303 See Other|所请求的页面可在别的url下被找到。
304 Not Modified|未按预期修改文档。客户端有缓冲的文档并发出了一个条件性的请求（一般是提供If-Modified-Since头表示客户只想比指定日期更新的文档）。服务器告诉客户，原来缓冲的文档还可以继续使用。

 `4XX 客户端错误`
消息:|描述:
:--:|:--:|
400 Bad Request|服务器未能理解请求。
401 Unauthorized|被请求的页面需要用户名和密码。
403 Forbidden|对被请求页面的访问被禁止。
404 Not Found|服务器无法找到被请求的页面。
405 Method Not Allowed|请求中指定的方法不被允许。
406 Not Acceptable|服务器生成的响应无法被客户端所接受。
407 Proxy Authentication Required|用户必须首先使用代理服务器进行验证，这样请求才会被处理。
408 Request Timeout|请求超出了服务器的等待时间。
409 Conflict|由于冲突，请求无法被完成。
413 Request Entity Too Large|由于所请求的实体的太大，服务器不会接受请求。
414 Request-url Too Long|由于url太长，服务器不会接受请求。当post请求被转换为带有很长的查询信息的get请求时，就会发生这种情况。

`5XX 服务器错误`
消息:|描述:
:--:|:--:|
500 Internal Server Error|请求未完成。服务器遇到不可预知的情况。
501 Not Implemented|请求未完成。服务器不支持所请求的功能。
502 Bad Gateway|请求未完成。服务器从上游服务器收到一个无效的响应。
503 Service Unavailable|请求未完成。服务器临时过载或当机。
504 Gateway Timeout|网关超时。
505 HTTP Version Not Supported|服务器不支持请求中指明的HTTP协议版本。


# 2. 浏览器缓存
## 1. 200 From cache和200 ok
为什么有的缓存是 200 OK (from cache)，有的缓存是 304 Not Modified 呢？很简单，看运维是否移除了 Entity Tag。移除了，就总是 200 OK (from cache)。没有移除，就两者交替出现。

其实， 200 OK (from cache)  是浏览器没有跟服务器确认，直接用了浏览器缓存；而 304 Not Modified 是浏览器和服务器多确认了一次缓存有效性，再用的缓存。

**它们都是在设置了缓存的情况下触发的。**

200 OK (from cache) 是直接点击链接访问，输入网址按回车访问也能触发；而 304 Not Modified 是刷新页面时触发，或是设置了长缓存、但 Entity Tags 没有移除时触发。

## 2. HTTP-304状态码--浏览器缓存
304状态码是在协商缓存，缓存命中的时候服务器返回的，告诉客户端，**服务器资源没有修改，可以使用客户端自己的缓存。**

浏览器缓存分为`强缓存`（本地缓存）和`协商缓存`（弱缓存）。
![](https://ttarea.com/post-images/1617850748410.png)

### 1. 强缓存
如上图所示，在浏览器第一次发出请求之后，需要再次发送请求的时候，浏览器首先获取该资源缓存的 header 信息，然后根据 Cache-Control 和 Expires 字段判断缓存是否过期。如果没有过期，直接使用浏览器缓存，并不会与服务器通信。该过程为判断是否使用`强缓存`，即本地缓存。

1. **Cache-Control**
该字段是 HTTP1.1 规范，一般利用该字段的 max-age 属性来判断，这个值是一个相对时间，单位为 s，代表资源的有效期。例如：
~~~
Cache-Control:max-age=3600
~~~
除此之外还有几个常用的值：
* no-cache：表示**不使用强缓存**，需要使用协商缓存
* no-store：禁止**浏览器缓存**数据，每次请求下载完整的资源
* public：可以被所有用户缓存，包括终端用户和中间代理服务器
* private：只能被终端用户的浏览器缓存


2. **Expires**
该字段是 HTTP1.0 规范，他是一个绝对时间的 GMT 格式的时间字符串。例如：
```
expires:Mar, 06 Apr 2021 10:57:09 GMT
```
这个时间代表资源的失效时间，只要发送请求的时间在这之前，都会使用强缓存。

由于失效时间是一个绝对时间，因此当**服务器时间与客户端时间偏差较大**时，就会导致**缓存混乱**。

### 2. 协商缓存
如果缓存过期，浏览器会向服务器发送请求，即使用`协商缓存`。本次请求会带着第一次请求返回的有关缓存的 header 字段信息，比如以下两个字段：

1. **Etag/If-None-Match**
判断响应头中是否存在 Etag 字段，如果存在，浏览器则发送一个带有 If-None-Match 字段的请求头的请求，该字段的值为 Etag 值。服务器通过对比**客户端发过来的Etag值是否与服务器相同**。如果相同，说明缓存命中，服务器**返回 304** 状态码，并将 If-None-Match 设为 false，客户端继续使用本地缓存。如果**不相同**，说明缓存未命中，服务器**返回 200 **状态码，并将 If-None-Match 设为 true，并且返回请求的数据。


2. Last-Modified/If-Modified-Since
除了 Etag 字段之外，客户端还会通过服务器返回的 Last-Modified 字段判断是否继续使用缓存，该字段为服务器返回的资源的最后修改时间，为UMT时间。浏览器发送一个带有 If-Modified-Since 字段的请求头的请求给服务器，该字段的值为 Last-Modified 值。服务器收到之后，通过这个时间判断，在该时间之后，资源有无修改，如果未修改，缓存命中，返回 304 状态码；如果未命中，返回 200 状态码，并返回最新的内容。

### 3. 知识点细节
`Cache-Control 与 Expires 的优先级：`

两者可以在服务端配置同时使用，**Cache-Control 的优先级高于 Expires。**

`为什么有了Last-Modified还要Etag`

Etag的出现主要是为了解决几个Last-Modified比较难解决的问题：
* Last-Modified标注的最后修改只能精确到秒级，如果某些文件在1秒钟以内，被修改多次的话，它将不能准确标注文件的修改时间
* 如果某些文件会被定期生成，当有时内容并没有任何变化，但Last-Modified却改变了，导致文件没法使用缓存
* 有可能存在服务器没有准确获取文件修改时间，或者与代理服务器时间不一致等情形

Last-Modified 和 Etag 可以一起使用，**Etag 的优先级更高。**

### 4. 刷新页面的问题：
F5刷新：不使用强缓存，使用协商缓存

ctrl+F5：二者都不使用


## 3. 缓存的资源去哪里了
`memory cache`JS等派生资源
>MemoryCache顾名思义，就是将资源缓存到内存中，等待下次访问时不需要重新下载资源，而直接从内存中获取。Webkit早已支持memoryCache。 
目前Webkit资源分成两类，一类是主资源，比如HTML页面，或者下载项，一类是派生资源，比如HTML页面中内嵌的图片或者脚本链接，分别对应代码中两个类：MainResourceLoader和SubresourceLoader。虽然Webkit支持memoryCache，但是也只是针对派生资源，它对应的类为CachedResource，用于保存原始数据（比如CSS，JS等），以及解码过的图片数据。

`disk cache`保存CSS等不频繁读取资源
DiskCache顾名思义，就是将资源缓存到磁盘中，等待下次访问时不需要重新下载资源，而直接从磁盘中获取，它的直接操作对象为CurlCacheManager。

*|memory cache|disk cache
:--:|:--:|:--:
相同点|只能存储一些派生类资源文件|只能存储一些派生类资源文件
不同点|退出进程时数据会被清除|退出进程时数据不会被清除
存储资源|一般脚本、字体、图片会存在内存当中|一般非脚本会存在内存当中，如css等

**因为CSS文件加载一次就可渲染出来,我们不会频繁读取它,所以它不适合缓存到内存中,但是js之类的脚本却随时可能会执行,如果脚本在磁盘当中,我们在执行脚本的时候需要从磁盘取到内存中来,这样IO开销就很大了,有可能导致浏览器失去响应。**

**三级缓存原理 (访问缓存优先级)**
1. 先在内存中查找,如果有,直接加载。
2. 如果内存中不存在,则在硬盘中查找,如果有直接加载。
3. 如果硬盘中也没有,那么就进行网络请求。
4. 请求获取的资源缓存到硬盘和内存。

**浏览器缓存的优点**
1. 减少了冗余的数据传输
2. 减少了服务器的负担，大大提升了网站的性能
3. 加快了客户端加载网页的速度


**总结**
当浏览器再次访问一个已经访问过的资源时，它会这样做：

1.看看是否命中强缓存，如果命中，就直接使用缓存了。

2.如果没有命中强缓存，就发请求到服务器检查是否命中协商缓存。

3.如果命中协商缓存，服务器会返回 304 告诉浏览器使用本地缓存。

4.否则，返回最新的资源。



# 3. DNS解析
## 1. 什么是DNS
全称 Domain Name System ,即域名系统。
>万维网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。DNS协议运行在UDP协议之上，使用端口号53。

## 2. DNS解析
通过域名,最终得到该域名对应的IP地址的过程叫做域名解析（或主机名解析）。
```
www.dnscache.com (域名) - DNS解析 -> 11.222.33.444 (IP地址)
```
`DNS解析步骤（缓存）`

1） 浏览器缓存　　
当用户通过浏览器访问某域名时，浏览器首先会在自己的缓存中查找是否有该域名对应的IP地址（若曾经访问过该域名且没有清空缓存便存在）；　　

2） 系统缓存　　
当浏览器缓存中无域名对应IP则会自动检查用户计算机系统Hosts文件DNS缓存是否有该域名对应IP；　

3） 路由器缓存　　
当浏览器及系统缓存中均无域名对应IP则进入路由器缓存中检查，以上三步均为客服端的DNS缓存；　　

4） DNS缓存　　
当在用户客服端查找不到域名对应IP地址，则将进入DNS缓存中进行查询。比如你用的是电信的网络，则会进入电信的DNS缓存服务器中进行查找；　　

5） 根域名服务器　　
当以上均未完成，则进入根服务器进行查询。全球仅有13台根域名服务器，1个主根域名服务器，其余12为辅根域名服务器。根域名收到请求后会查看区域文件记录，若无则将其管辖范围内顶级域名（如.com）服务器IP告诉本地DNS服务器；　　

6） 顶级域名服务器　　
顶级域名服务器收到请求后查看区域文件记录，若无则将其管辖范围内主域名服务器的IP地址告诉本地DNS服务器；　　

7） 主域名服务器　　
主域名服务器接受到请求后查询自己的缓存，如果没有则进入下一级域名服务器进行查找，并重复该步骤直至找到正确纪录；　　

8）保存结果至缓存　　
本地域名服务器把返回的结果保存到缓存，以备下一次使用，同时将该结果反馈给客户端，客户端通过这个IP地址与web服务器建立链接。



# 4. CDN（内容分发网络）
## 1. 什么是CDN
简单的理解CDN就是这些缓存服务器，帮助在最近的CDN节点，用最短的请求时间拿到资源，这样排队的人也就少了。也就起到分流作用，减轻服务器负载压力。

## 2. CDN工作原理
`资源上传cdn之后，当用户访问cdn的资源地址之后会经历下面的步骤：`
1. 首先经过本地的dns解析，请求cname指向的那台cdn专用的dns服务器。
2. dns服务器返回全局负载均衡的服务器ip给用户
3. 用户请求全局负载均衡服务器，服务器根据ip返回所在区域的负载均衡服务器ip给用户
4. 用户请求区域负载均衡服务器，负载均衡服务器根据用户ip选择距离近的，并且存在用户所需内容的，负载比较合适的一台缓存服务器ip给用户。当没有对应内容的时候，会去上一级缓存服务器去找，直到找到资源所在的源站服务器，并且缓存在缓存服务器中。用户下一次在请求该资源，就可以就近拿缓存了。

![](https://ttarea.com/post-images/1626742657399.png)
cdn的原理主要答出`负载均衡`和`缓存`再就是`dns解析`这三部分就行了吧，通过`dns解析`到`全局负载均衡服务器`，然后再到`区域的负载均衡`，之后根据一些条件来找合适的`缓存服务器`，如果第一次访问就从源站拿过来缓存。 需要注意的是一切都是根据请求的ip来的，如果ip不合理，那么可能起不到加速效果。缓存和负载均衡的思想在减轻服务器压力方面其实是很常见的。

**从这个例子可以了解到：**
（1）CDN的加速资源是跟域名绑定的。
（2）通过域名访问资源，首先是通过DNS分查找离用户最近的CDN节点（边缘服务器）的IP
（3）通过IP访问实际资源时，如果CDN上并没有缓存资源，则会到源站请求资源，并缓存到CDN节点上，这样，用户下一次访问时，该CDN节点就会有对应资源的缓存了。

## 3. CDN缓存
关于CDN缓存,在浏览器本地缓存失效后,浏览器会向CDN边缘节点发起请求。类似浏览器缓存,CDN边缘节点也存在着一套缓存机制。CDN边缘节点缓存策略因服务商不同而不同，但一般都会遵循http标准协议，通过http响应头中的
```
Cache-control: max-age //后面会提到
```
的字段来设置CDN边缘节点数据缓存时间。

## 4. CDN 优势
CDN节点解决了跨运营商和跨地域访问的问题，访问延时大大降低。
大部分请求在CDN边缘节点完成，CDN起到了分流作用，减轻了源服务器的负载。



# 5. 网络结构 与 HTTP 协议
![](https://ttarea.com/post-images/1616399158170.gif)
有两套参考模型：
* OSI参考模型（Open Systems Interconnection Reference Model，七层）：模型过于理想化，未能在因特网上进行广泛推广。
* TCP/IP参考模型(或TCP/IP协议，四层)：事实上的国际标准。
![](https://ttarea.com/post-images/1615458129735.png)
## 1. HTTP轮询（即时通讯）
### 1. 轮询
短轮询的基本思路就是**浏览器每隔一段时间向浏览器发送http请求，服务器端在收到请求后，不论是否有数据更新，都直接进行响应**。这种方式实现的即时通信，本质上还是浏览器发送请求，服务器接受请求的一个过程，通过让客户端不断的进行请求，使得客户端能够模拟实时地收到服务器端的数据的变化。

这种方式的优点是比较简单，易于理解，实现起来也没有什么技术难点。缺点是显而易见的，这种方式由于需要不断的建立http连接，**严重浪费了服务器端和客户端的资源**。尤其是在客户端，距离来说，如果有数量级想对比较大的人同时位于基于短轮询的应用中，那么每一个用户的客户端都会疯狂的向服务器端发送http请求，而且不会间断。人数越多，服务器端压力越大，这是很不合理的。

因此短轮询不适用于那些同时在线用户数量比较大，并且很注重性能的Web应用。
```
var xhr = new XMLHttpRequest();
    setInterval(function(){
        xhr.open('GET','/user');
        xhr.onreadystatechange = function(){

        };
        xhr.send();
    },1000)
```
### 2. 长轮询（ajax实现）
当服务器收到客户端发来的请求后，**服务器端不会直接进行响应，而是先将这个请求挂起，然后判断服务器端数据是否有更新**。如果有更新，则进行响应，如果一直没有数据，则到达一定的时间限制(服务器端设置)才返回。客户端JavaScript响应处理函数会在处理完服务器返回的信息后，再次发出请求，重新建立连接。

长轮询和短轮询比起来，明显减少了很多不必要的http请求次数，相比之下节约了资源。**长轮询的缺点在于，连接挂起也会导致资源的浪费**。
```
   function ajax(){
        var xhr = new XMLHttpRequest();
        xhr.open('GET','/user');
        xhr.onreadystatechange = function(){
              ajax();
        };
        xhr.send();
    }
```
轮询与长轮询都是基于HTTP的，两者本身存在着缺陷：轮询需要更快的处理速度；长轮询则更要求处理并发的能力；两者都是“**被动型服务器**”的体现：服务器不会主动推送信息，而是在客户端发送ajax请求后进行返回的响应。而理想的模型是"在服务器端数据有了变化后，可以主动推送给客户端"，这种"**主动型**"服务器是解决这类问题的很好的方案。

## 2. HTTP建立持久连接的意义
在 HTTP1.0 中每发送一次请求都要重新建立 TCP 连接并且关闭连接。这样做是很耗费时间的。而在HTTP1.1 中默认开启长连接，一次TCP连接可以发送多个HTTP请求，避免了重复建立释放连接的开销，加速了数据的传输，节省了时间和带宽。

### 1.那么长连接什么时候会释放呢？

客户端的长连接不可能一直拿着，会有一个超时时间，服务器会告诉客户端超时时间，譬如：
```
Access-Control-Allow-Origin: http://mall.sillywa.com
Connection: keep-alive
Content-Length: 43574
Content-Type: application/json; charset=utf-8
Date: Wed, 03 Mar 2021 07:34:49 GMT
Keep-Alive: timeout=5
Vary: Origin
```
**Keep-Alive: timeout=5** **表示这个 TCP 通道可以保持 5s**。另外还可能有 max=xxx，表示这个长连接**最多接受xxx次请求就断开**。对于客户端来说，如果服务端没有告诉是客户端超时时间也没关系，服务端可能主动发起四次挥手断开TCP连接，客户端就能够知道该TCP连接已经无效。

### 2. 长连接数据传送完成识别：
1. 判断传输的数据是否达到了 Content-Length 指示的大小
2. 没有 Content-Length，由于数据是分块传输的，这时候就要根据块的编码来判断了，最后一个一个编码的数据是一个空块，表明本次传输结束


## 3. HTTP报文结构
HTTP报文由**报文首部**和**报文主体**构成，中间由一个**空行分隔**。**报文首部包含请求行和请求头部**，报文主体主要包含被发送的信息。

报文首部是客户端或服务端需要处理请求或响应的内容及属性，可以传递额外的信息。

### 1.1 HTTP请求报文
HTTP请求报文由3部分组成（请求行+请求头+请求体）：
![](https://ttarea.com/post-images/1617847556323.jpg)

**请求行：**
①是`请求方法`，GET和POST是最常见的HTTP方法，除此以外还包括DELETE、HEAD、OPTIONS、PUT、TRACE。
②为请求对应的`URL地址`，它和报文头的Host属性组成完整的请求URL。
③是`协议名称及版本号`。

**请求头：**
④是`HTTP的报文头`，报文头包含若干个属性，格式为“属性名:属性值”，服务端据此获取客户端的信息。
与缓存相关的规则信息，均包含在header中

**请求体：**
⑤是`报文体`，它将一个页面表单中的组件值通过param1=value1&param2=value2的键值对形式编码成一个格式化串，它承载多个请求参数的数据。不但报文体可以传递请求参数，请求URL也可以通过类似于“/chapter15/user.html? param1=value1&param2=value2”的方式传递请求参数。 


### 1.2 HTTP响应报文
HTTP的响应报文也由三部分组成（响应行+响应头+响应体）
![](https://ttarea.com/post-images/1617847696959.jpg)

**响应行：**
①报文协议及版本； 
②状态码及状态描述；

**响应头：**
③响应报文头，也是由多个属性组成；

**响应体：**
④响应报文体，即我们真正要的“干货”


## 4. HTTP首部字段
### 1. HTTP通用首部字段
通用首部字段是请求报文和响应报文都会使用的字段，例如：
通用头部字段|HTTP1.0|HTTP1.1|含义
:--:|:--:|:--:|:--:
Date|有| |表示请求和响应生成的日期，GTM时间。例如 Tue, 02 Mar 2021 12:31:25 GMT
Pragma|有| |表示数据是否允许被缓存的通信选项
Cache-Control| |有|控制缓存的相关信息
Connection| |有|设置发送响应之后 TCP 连接是否继续保持
Transfer-Encoding| |有|表示消息主体的编码格式
Via| |有|记录途中经过的代理和网关

### 2 HTTP请求首部字段
请求头部字段|HTTP1.0|HTTP1.1|含义
:--:|:--:|:--:|:--:
Host| |有|接受请求的服务器IP地址和端口号
Accept|有|有|客户端可支持的数据类型
User-Agent|有|有|客户端软件的名称和版本号等相关信息
If-Modified-Since|有|有|UMT时间，表示该时间之后资源是否修改
If-None-Match| |有|返回服务器响应头的 Etag 值
Referer|有|有|通过点击超链接进入下一个页面时，在这里会记录上一个页面的 URI
Accept-Encoding|有|有|客户端可支持的编码格式
Accept-Language|有|有|客户端可支持的语言
If-Match| |有|	
If-Unmodified-Since| |有|	
Range| |有|当只需要回去部分数据时，可通过这个字段指定要获取的数据范围

### 3. HTTP响应首部字段
响应头部字段|HTTP1.0|HTTP1.1|含义
:--:|:--:|:--:|:--:
Location|有|有|表示信息的准确位置，绝对路径
Server|有|有|服务器程序的名称和版本号相关信息

### 4 HTTP实体（消息体）首部字段
实体头部字段|HTTP1.0|HTTP1.1|含义
:--:|:--:|:--:|:--:
Allow|有|有|表示指定的 URI 支持的方法
Content-Encoding|有|有|消息的编码格式
Content-Length|有|有|消息体的长度
Content-Type|有|有|消息体的数据类型
Expires|有|有|消息体的有效期，UMT 时间
Last-Modified|有|有|数据最后更新的日期
Etag| |有|资源的唯一标识符，控制是否使用缓存

## 5. HTTP1.0与HTTP1.1以及HTTP2.0相关知识
### 1. HTTP 1.0
HTTP 协议老的标准是HTTP/1.0，是一种无状态，无连接的应用层协议。 为了提高系统的效率，HTTP 1.0规定浏览器与服务器只保持**短暂的连接**，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接，服务器不跟踪每个客户也不记录过去的请求。

在HTTP1.0默认是短连接；简单来说就是：每次与服务器交互，都需要新开一个连接！
![](https://ttarea.com/post-images/1626872405629.jpg)
![](https://ttarea.com/post-images/1626872408887.jpg)

基于此会发现，http1.0被抱怨最多的就是**连接无法复用**和**队头阻塞（head of line blocking）**
>由于HTTP1.0规定下一个请求必须在前一个请求响应到达之前才能发送，假设前一个请求响应一直不到达，那么下一个请求就不发送，后面的请求就阻塞了。

### 2. HTTP 1.1
在HTTP1.1中默认就使用持久化连接来解决：**建立一次连接，多次请求均由这个连接完成！**(如果阻塞了，还是会开新的TCP连接的)

HTTP1.1增加Connection字段，通过设置**Keep-Alive**保持HTTP连接不断。避免每次客户端与服务器请求都要重复建立释放建立TCP连接。提高了网络的利用率。

如果客户端想关闭HTTP连接，可以在请求头中携带Connection:false来告知服务器关闭请求。
![](https://ttarea.com/post-images/1626872730153.png)

HTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地减少了整个下载过程所需要的时间。

相对于持久化连接还有另外比较重要的改动：
* HTTP 1.1增加host字段
* HTTP 1.1中引入了Chunked transfer-coding，范围请求，实现断点续传(实际上就是利用HTTP消息头使用分块传输编码，将实体主体分块传输)
* HTTP 1.1管线化(pipelining)理论，客户端可以同时发出多个HTTP请求，而不用一个个等待响应之后再请求

### 3. HTTP 2.0
在说HTTP2之前，不如先直观比较一下HTTP2和HTTP1.1的区别：
![](https://ttarea.com/post-images/1626874953559.gif)
上面也已经说了，HTTP 1.1提出了**管线化(pipelining)理论**，但是仅仅是限于理论的阶段上，这个功能默认还是`关闭`了的。

所以说，无论是HTTP1.0还是HTTP1.1提出了Pipelining理论，还是会出现阻塞的情况。从专业的名词上说这种情况，叫做**线头阻塞**（Head of line blocking）简称：HOLB

#### 1. 多路复用 与 二进制传输
HTTP2与HTTP1.1最重要的区别就是解决了线头阻塞的问题！其中最重要的改动是：**多路复用 (Multiplexing)**

而HTTP2所有性能增强的`核心`在于新的`二进制分帧`层(不再以文本格式来传输了)，它定义了如何封装http消息并在客户端与服务器之间传输。

HTTP/2 采用二进制格式传输数据，而非HTTP/1.x 里纯文本形式的报文 ，二进制协议解析起来更高效。**HTTP/2 将请求和响应数据分割为更小的帧，并且它们采用二进制编码。**

它把TCP协议的部分特性挪到了应用层，把原来的"Header+Body"的消息"打散"为数个小片的二进制"帧"(Frame)，用"HEADERS"帧存放头数据、"DATA"帧存放实体数据。HTP/2数据分帧后"Header+Body"的报文结构就完全消失了，协议看到的只是一个个的"碎片"。
![](https://ttarea.com/post-images/1626875923219.png)
![](https://ttarea.com/post-images/1626875879453.png)
HTTP/2 中，同域名下所有通信都在单个连接上完成，该连接可以承载任意数量的双向数据流。每个数据流都以消息的形式发送，而消息又由一个或多个帧组成。**多个帧之间可以乱序发送，根据帧首部的流标识可以重新组装**。

![](https://ttarea.com/post-images/1616381290207.jpg)
如上图所示，多路复用的技术可以只通过一个 TCP 连接就可以传输所有的请求数据。

#### 2. Header 压缩
HTTP/2并没有使用传统的压缩算法，而是开发了专门的"HPACK”算法，在客户端和服务器两端建立“字典”，用索引号表示重复的字符串，还采用哈夫曼编码来压缩整数和字符串，可以达到50%~90%的高压缩率。

**具体来说:**
* 在客户端和服务器端使用“首部表”来跟踪和存储之前发送的键-值对，对于相同的数据，不再通过每次请求和响应发送；
* 每次只发送改变的（需要更新的）数据字段即可

例如下图中的两个请求， 请求一发送了所有的头部字段，第二个请求则只需要发送差异数据，这样可以减少冗余数据，降低开销
![](https://ttarea.com/post-images/1616380864613.png)
![](https://ttarea.com/post-images/1626876168090.png)

### 3. 服务器推送
服务器除了最初请求的响应外，服务器还可以额外向客户端推送资源，而无需客户端明确的需求。

可以在客户端请求index.html的时候，就主动推送后面需要用到的所有静态资源给客户端，并存储在缓存中，大大改善加载时间。
![](https://ttarea.com/post-images/1617865820470.jpg)

## 6. 对称加密、非对称加密、公钥、私钥、数字签名、数字证书
### 1. 对称数据加密
![](https://ttarea.com/post-images/1619659703397.png)
就像上图所示， 这加密和解密算法是公开的，那个密钥是保密的， 只有两人才知道， 这样生成的加密消息（密文） 别人就无法得知了。这叫对称加密算法，因为加密和解密用的是同一个密钥。

问题来了，这个密钥的双方必须得知道，但是通过网络发送又不安全，这该怎么办呢？这时候就出现了非对称数据加密。

### 2. RSA：非对称加密
这个RSA算法非常有意思，它不是像之前的算法， 双方必须协商一个保密的密钥， 而是有一对儿钥匙， 一个是保密的，称为私钥，另外一个是公开的，称为公钥。

更有意思的是，用私钥加密的数据，只有对应的公钥才能解密，用公钥加密的数据， 只有对应的私钥才能解密。
![](https://ttarea.com/post-images/1619659810918.png)
当张大胖给Bill发消息的时候， 就可以先用Bill的公钥去加密（反正Bill的公钥是公开的，地球人都知道）， 等到消息被Bill 收到后， 他就可以用自己的私钥去解密（只有Bill才能解开，私钥是保密的 ）【也就是A发送消息给B时候，利用B的公钥，然后B收到后利用私钥解密接收。】
![](https://ttarea.com/post-images/1619659898143.png)
反过来也是如此， 当Bill 想给张大胖发消息的时候，就用张大胖的公钥加密， 张大胖收到后，就用自己的私钥解密。


### 3. 非对称加密+对称加密
因为RSA的加密和解密的速度比较慢，RSA的算法比之前的对称密钥算法要慢上百倍。

回到咱们最初的问题，我们想用一个密钥来加密通信，那个对称加密算法是非常快的，但是苦于密钥无法安全传输， 现在有了RSA ，我想可以结合一下， 分两步走　(1) 我生成一个对称加密算法的密钥， 用RSA的方式安全发给你， (2) 我们随后就不用RSA了， 只用这个密钥，利用对称加密算法来通信，这样即可以保证安全又可以加快速度。【也就是只利用RSA传输密钥，保证密钥的安全。然后利用对称加密进行信息传输。】

这样以来既解决了密钥的传递问题， 又解决了RSA速度慢的问题，不错。

于是两人就安全地传递了对称加密的密钥， 用它来加密解密，果然快多了！

`HTTPS就是使用上述混合加密的方法。`

### 4. 中间人攻击
![](https://ttarea.com/post-images/1619660545440.png)
**看来问题出现在公钥的分发上**虽然这个东西是公开的，但是在别有用心的人看来，截取以后还可以干坏事 ！
但是怎么安全地分发公钥呢？ 似乎又回到了最初的问题： 怎么安全的保护密钥（之前是利用非对称保护私钥的传输，现在是考虑如何保证公钥的发送方）？

可是似乎和最初的问题还不一样，这一次的公钥不用保密，但是一定得有个办法声明这个公钥确实是Bill的， 而不是别人的。

### 5. 信息摘要、数字签名、数字证书
简单来讲是这样的， Bill可以把他的公钥和个人信息用一个Hash算法生成一个消息摘要， 这个Hash算法有个极好的特性，只要输入数据有一点点变化，那生成的消息摘要就会有巨变，这样就可以防止别人修改原始内容。
![](https://ttarea.com/post-images/1619660931513.png)
我们会让有公信力的认证中心（简称CA）用它的私钥对消息摘要加密，形成签名：
![](https://ttarea.com/post-images/1619660885193.png)
这还不算， 还把**原始信息**和**数据签名**合并， 形成一个全新的东西，叫做“数字证书”
![](https://ttarea.com/post-images/1619660980624.png)
张大胖接着说：当Bill把他的证书发给我的时候， 我就用同样的Hash 算法， 再次生成消息摘要，然后用CA的公钥对数字签名解密， 得到CA创建的消息摘要， 两者一比，就知道有没有人篡改了！

如果没人篡改， 我就可以安全的拿到Bill的公钥喽，有了公钥， 后序的加密工作就可以开始了。
![](https://ttarea.com/post-images/1619661151582.png)
那么这个CA的公钥怎么保证他的安全性？

附注：我们利用上面数字证书保证传输安全的前提就是，我们默认CA的公钥是安全的。因为CA的公钥安全，所以得出的消息摘要是安全的，这就可以与Hash算法得出的消息摘要比较是否相同，从而确保消息的安全的。

## 7. HTTP与HTTPS的区别及实现方式
### 1. 基本概念
**HTTP是超文本传输协议**，是一个简单的`请求-响应协议`，它默认工作在TCP的80端口。**它指定了客户端可能发送给服务器什么样的消息以及得到什么样的响应**。协议以明文的方式进行发送，不提供任何方式的数据加密。因此HTTP协议不适合传输一些敏感信息

**HTTPS是超文本传输安全协议**，是一种`安全通信`的传输协议。**HTTPS经由HTTP进行通信，但利用 SSL/TSL 来进行加密数据包**。HTTPS开发的主要目的是提供网站服务器的身份认证，保护数据交换的隐私与完整性。

HTTPS默认工作在 TCP 的443 端口，它的工作方式如下：
* TCP三次同步握手
* 客户端验证服务端数字证书
* DH 算法协商对称加密加密算法的密钥、hash 算法的密钥
* SSL 安全加密隧道协商完成
* 网页以加密的方式进行传输，用协商的对称加密算法和密钥加密，保障数据机密性；用协商的 hash 算法进行数据完整性保护，保证数据不被篡改。

### 2. HTTP的无状态
**就是第二次来你无法识别它曾经来过**

**http的每次请求，在事务上和前后http请求没有任何关联，对上一次请求，下一次请求没有任何影响。这个是定义，从宏观上说的，实际上把无状态说成请求独立，无关联也对**

HTTP 是一个无状态协议，这意味着`每个请求都是独立`的，Keep-Alive 没能改变这个结果。

缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。

HTTP 协议这种特性有优点也有缺点，优点在于解放了服务器，每一次请求“点到为止”不会造成不必要连接占用，缺点在于每次请求会传输大量重复的内容信息。

HTTP 无状态的特性严重阻碍了这些应用程序的实现，于是两种用于保持 HTTP 连接状态的技术就应运而生了，一个是 `Cookie`，而另一个则是 `Session`。

![](https://ttarea.com/post-images/1619491336853.png)
![](https://ttarea.com/post-images/1619491341437.png)

### 3. HTTP 与 HTTPS 的区别
* HTTP 使用明文传输，数据都是**未加密**的，安全性较差；HTTPS 数据传输过程是加密的，安全性较好；
* 使用 HTTPS 一般需要到 **CA 申请证书**
* HTTP页面的响应比 HTTPS **快**，主要是因为 HTTPS 除了 TCP 的三个包之外，还要加上 ssl 握手的 9 个包
* HTTP 和 HTTPS 是完全不同连接方式，用的端口也不一样， 前者是80， 后者是 443
* HTTPS 其实就是建构在 SSL/TSL 之上的 HTTP 协议，所以要比 HTTP **更消耗服务器资源**


### 4. HTTPS 的工作方式
![](https://ttarea.com/post-images/1617862416374.png)
1. 客户端发起 HTTPS 请求
建立TCP连接之后，客户端发起请求
2. 服务端的配置
服务端收到请求之后，会有一套公钥和私钥，这对公钥和私钥其实就是一套数字证书，一般都是由受信任的证书颁发机构进行签发。
3. 传送公钥
服务端将公钥传递给客户端，里面包含很多信息，如证书的颁发机构，证书的过期时间
4. 客户端解析证书
这部分工作由客户端的 TSL 来完成，首先验证证书是否有效。如果没有问题，就会随机生成一个 key，然后利用公钥对 key 的值进行加密。
5. 传送加密的信息（key）
将加密过后的 key 传递给服务器
6. 使用私钥解析加密信息（key）
服务器使用自己的私钥解密加密信息得到 key
7. 使用客户端的 key，利用对称加密加密信息，并发送给客户端
把内容通过该 key 进行对称加密，并传输给客户端
8. 客户端使用 key 解密信息
客户端收到信息之后利用 key 进行解密

**重点：客户端会生成 key，key 的传输使用非对称加密，而数据的传输使用 key 进行对称加密。**
**对称加密：加密密钥和解密密钥是同一个，效率较高**
**非对称加密：加密密钥和解密密钥不是同一个，效率较低**

由于`非对称加密的效率比较低`，因此我们通常不使用非对称加密对整个文件进行加密，而采用`对称加密对文件加密`，`非对称加密对对称加密的密钥加密`，然后将`对称加密后的文件和非对称加密后的密钥`一起在网上传送。

### 5. SSL 的位置
![](https://ttarea.com/post-images/1617863364032.png)
在发送方，SSL接受应用层的数据（如HTTP或者IMAP报文），对数据进行加密，然后把加了密的数据送往TCP套接字。

在接收方，SSL从TCP套接字读取数据，解密后把数据交给应用层。

使用非对称加密进行文件传输。通信双方在传输时需要交换各自的公钥。

**SSL提供以下三个功能：**
（1）SSL服务器鉴别：允许用户证实服务器的身份。具有SSL功能的浏览器维持一个表，上面有一些可信赖的认证中心CA（Certificate Authority）和它们的公钥。
（2）加密的SSL会话：客户和服务器交互的所有数据都在发送方加密，在接收方解密。
（3）SSL客户鉴别：允许服务器证实客户的身份。





# 6. TCP/IP 和 UDP 协议
## 1. TCP/IP 协议分层管理
![](https://ttarea.com/post-images/1617869165303.png)
传输层：可靠传输（丢包重发） 、流量控制、不可靠传输（只需要发送一个数据包）

网络层：负责选择最佳路径、规划 IP 地址

数据链路层：帧的开始和结束、透明传输（数据中出现了帧的结束标志，需要采用转义字符）、差错校验（循环冗余检测）

## 2. TCP三次握手四次挥手机制及原因
### 1. 连接中怎么找到对方？
**TCP头部为20字节**
* 源端口号（16位）和目的端口号（16位）：`再加上Ip首部的源IP地址和目的IP地址可以唯一确定一个TCP连接` 
* 数据序号（16位）：表示在这个报文段中的第一个数据字节序号
* 确认序号：仅当ACK标志为1时有效，确认号表示期望收到的下一个字节的序号
* 偏移：就是头部长度，有4位，跟IP头部一样，以4字节为单位。最大是60个字节
* 保留位：6位，必须为0
* 6个标志位：URG-紧急指针有效；ACK-确认序号有效；PSH-接收方应尽快将这个报文交给应用层；RST-连接重置；SYN-同步序号用来发起一个连接；FIN-终止一个连接。
* 窗口字段：16位，代表的是窗口的字节容量，也就是TCP的标准窗口最大为2^16 - 1 = 65535个字节
* 校验和：源机器基于数据内容计算一个数值，收信息机要与源机器数值结果完全一样，从而证明数据的有效性。检验和覆盖了整个的TCP报文段：这是一个强制性的字段，一定是由发送端计算和存储，并由接收端进行验证的。


### 2. 三次握手
![](https://ttarea.com/post-images/1617869541484.png)

**为什么需要三次握手，两次行不行？**

假设是两次握手，客户端刚开始发送第一个建立连接的请求，但是由于该请求在某一个路由器中停留时间过长，客户端一段时间没收到服务器的响应消息，就会再发一个建立连接的请求，这个请求达到服务器，并成功建立连接，之后数据传输完成，关闭连接。这时候先前发送的第一个建立连接的请求，终于通过网络传到了服务器，服务器收到请求，返回一个数据包，并立即打开连接，这是客户端已经关闭了，对服务端的数据包不予理睬，这样就会导致服务端资源的浪费。

**为什么不能四次握手？**
四次握手的流程：

1. 客户端发送：SYN=1,ACK=0,seq=x
2. 服务端收到客户端消息，发送：ACK = 1, 确认号=x+1,seq=y
3. 服务端发送同步建立连接，发送：SYN=1，确认号=x+1，seq = w
4. 客户端收到发送：ACK=1，确认号=w+1,seq = x+1

在这个过程中，显然第二步和第三步可以合并，不需要单独发送一个 SYN


### 3. 四次挥手
![](https://ttarea.com/post-images/1617870529977.png)
既然握手的时候，服务端发送的两个请求可以合并，**那么释放连接的时候，是否也能合并，只需三次握手呢？**

我们的回答是不能够，因为当服务器收到客户端关闭连接的请求的时候，服务端可能还在继续发送数据，但是他又必须先给客户端一个回应，说我收到了请求。等服务端的数据发送完毕之后，再发一个数据包说我已经可以关闭请求了。客户端收到之后再作出回应。

**客户端为什么要有TIME-WAIT阶段**？

防止最后一个数据包丢失而导致服务器接收不到，一段时间后服务器会重新发送第三个数据包。如果此时客户端已经关闭了，则收不到第三个数据包，服务端也就无法正常关闭了。


## 3.TCP/UDP 的区别
TCP|UDP
:--:|:--:
面向连接，是指发送数据之前必须在两端建立TCP连接，连接方式为三次握手|不面向连接
可靠传输，流量控制与拥塞控制|不可靠传输，尽最大努力交付
传输方式上以字节流的形式传输|以报文形式传输
只能是一对一通信|支持一对一、一对多、多对多、多对一交互通信
最小20字节，最多60字节|首部开销较小，只有 8 字节
适用于要求可靠传输的应用|**适用于实时应用，如视频会议、直播等**




# 7. GET,POST,PUT,DELETE,OPTIONS等请求方式
## 1. 不同请求方式区别
### 1. GET
get请求是用来获取数据的，只是用来`查询数据`，不对服务器的数据做任何的修改，新增，删除等操作。

在这里我们认为get请求是`安全的`，以及`幂等的`。安全就是指不影响服务器的数据，幂等是指同一个请求发送多次返回的结果应该相同。

**特点：**
1. get请求会把请求的参数附加在URL后面，这样会产生安全问题，如果是系统的登陆接口采用的get请求，需要对请求的参数做一个加密。
2. get请求其实本身HTTP协议并没有限制它的URL大小，但是不同的浏览器对其有不同的大小长度限制


### 2. POST
post请求一般是对服务器的数据做改变，常用来数据的提交，新增操作。

**特点：**
1. post请求的请求参数都是请求体中
2. post请求本身HTTP协议也是没有限制大小的，限制它的是服务器的处理能力

### 3. PUT
put请求与post一样都会改变服务器的数据，但是put的侧重点在于对于数据的修改操作，但是post侧重于对于数据的增加。

### 4. DELETE
delete请求用来删除服务器的资源。

### 5. OPTIONS
options请求属于浏览器的`预检请求`，查看服务器是否接受请求，预检通过后，浏览器才会去发get，post，put，delete等请求。至于什么情况下浏览器会发预检请求，浏览器会会将请求分为两类，简单请求与非简单请求，`非简单请求`会产生预检options请求。(结合CORS跨域)

## 2. 浏览器的GET和POST
浏览器用GET请求来获取一个html页面/图片/css/js等资源；用POST来提交一个<form>表单，并得到一个结果的网页。

### 1. GET
“读取“一个资源。比如Get到一个html文件。反复读取不应该对访问的数据有副作用。没有副作用被称为“幂等“（Idempotent)。因为GET因为是读取，就可以对GET请求的数据做缓存。这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），或者做到server端（用Etag，至少可以减少带宽消耗）

### 2. POST
在页面里\<form> 标签会定义一个表单。点击其中的submit元素会发出一个POST请求让服务器做一件事。这件事往往是有副作用的，`不幂等`的。不幂等也就意味着不能随意多次执行。因此也就不能缓存。

此外如果尝试重新执行POST请求，浏览器也会弹一个框提示下这个刷新可能会有副作用，询问要不要继续。
![](https://ttarea.com/post-images/1618324396186.jpg)

### 3. 区别
`GET和POST携带数据的格式也有区别`。当浏览器发出一个GET请求时，就意味着要么是用户自己在浏览器的地址栏输入，要不就是点击了html里a标签的href中的url。所以其实并不是GET只能用url，而是浏览器直接发出的GET只能由一个url触发。所以没办法，GET上要在url之外带一些参数就只能依靠url上附带querystring。但是HTTP协议本身并没有这个限制。

`浏览器的POST请求都来自表单提交`。每次提交，表单的数据被浏览器用编码到HTTP请求的body里。浏览器发出的POST请求的body主要有有两种格式，一种是application/x-www-form-urlencoded用来传输简单的数据，大概就是"key1=value1&key2=value2"这样的格式。另外一种是传文件，会采用multipart/form-data格式。采用后者是因为application/x-www-form-urlencoded的编码方式对于文件这种二进制的数据非常低效。

浏览器在POST一个表单时，url上也可以带参数，只要\<form action="url" >里的url带querystring就行。只不过表单里面的那些用\<input> 等标签经过用户操作产生的数据都在会在body里。


## 3. 接口中的GET和POST
这里是指通过浏览器的Ajax api，或者iOS/Android的App的http client，java的commons-httpclient/okhttp或者是curl，postman之类的工具发出来的GET和POST请求。此时GET/POST不光能用在前端和后端的交互中，还能用在后端各个子服务的调用中（即当一种RPC协议使用）。尽管RPC有很多协议，比如thrift，grpc，但是http本身已经有大量的现成的支持工具可以使用，并且对人类很友好，容易debug。HTTP协议在微服务中的使用是相当普遍的。

当用HTTP实现接口发送请求时，就`没有浏览器中那么多限制`了，只要是符合HTTP格式的就可以发。HTTP请求的格式，大概是这样的一个字符串（为了美观，我在\r\n后都换行一下）：
```
<METHOD> <URL> HTTP/1.1\r\n
<Header1>: <HeaderValue1>\r\n
<Header2>: <HeaderValue2>\r\n
...
<HeaderN>: <HeaderValueN>\r\n
\r\n
<Body Data....>
```
接口规范/风格。其中名气最大的当属REST。REST充分运用GET、POST、PUT和DELETE，约定了这4个接口分别获取、创建、替换和删除“资源”，REST最佳实践还推荐在请求体使用json格式。这样仅仅通过看HTTP的method就可以明白接口是什么意思，并且解析格式也得到了统一。

>json相对于x-www-form-urlencoded的优势在于
1）可以有嵌套结构；
2）可以支持更丰富的数据类型。通过一些框架，json可以直接被服务器代码映射为业务实体。用起来十分方便。但是如果是写一个接口支持上传文件，那么还是multipart/form-data格式更合适。

REST中GET和POST不是随便用的。在REST中, 【GET】 + 【资源定位符】被专用于获取资源或者资源列表，比如：
```
GET http://foo.com/books          获取书籍列表
GET http://foo.com/books/:bookId  根据bookId获取一本具体的书
```

REST 【POST】+ 【资源定位符】则用于“创建一个资源”，比如：
```
POST http://foo.com/books
{
  "title": "大宽宽的碎碎念",
  "author": "大宽宽",
  ...
}
```
这里你就能留意到**浏览器中用来实现表单提交的POST**，和REST里实现创建资源的POST语义上的不同。


## 4. 关于安全性
我们常听到GET不如POST安全，因为POST用body传输数据，而GET用url传输，更加容易看到。但是从攻击的角度，无论是GET还是POST都不够安全，因为HTTP本身是`明文协议`。`每个HTTP请求和返回的每个byte都会在网络上明文传播，不管是url，header还是body`。这完全不是一个“是否容易在浏览器地址栏上看到“的问题。

为了避免传输中数据被窃取，`必须做从客户端到服务器的端端加密。业界的通行做法就是https`——即用SSL协议协商出的密钥加密明文的http数据。这个加密的协议和HTTP协议本身相互独立。如果是利用HTTP开发公网的站点/App，要保证安全，https是最最基本的要求。

从客户端到服务器端，有大量的中间节点，包括网关，代理等。他们的access log通常会输出完整的url，比如nginx的默认access log就是如此。如果url上携带敏感数据，就会被记录下来。但请注意，`就算私密数据在body里，也是可以被记录下来的`，因此如果请求要经过不信任的公网，避免泄密的`唯一手段就是https`。这里说的“避免access log泄漏“仅仅是指避免可信区域中的http代理的默认行为带来的安全隐患。
![](https://ttarea.com/post-images/1618325278742.jpg)

## 5. 关于URL的长度
因为上面提到了不论是GET和POST都可以使用URL传递数据，所以我们常说的“GET数据有长度限制“其实是指”URL的长度限制“。

HTTP协议本身对URL长度并没有做任何规定。实际的限制是由客户端/浏览器以及服务器端决定的。

先说浏览器。不同浏览器不太一样。比如我们常说的2048个字符的限制，其实是IE8的限制。并且原始文档的说的其实是“URL的最大长度是2083个字符，path的部分最长是2048个字符“。Chrome的URL限制是2MB

除了浏览器，服务器这边也有限制，比如apache的LimieRequestLine指令。

apache实际上限制的是HTTP请求第一行“Request Line“的长度，即\<METHOD>\<URL> \<VERSION>那一行。再比如nginx用`large_client_header_buffers` 指令来分配请求头中的很长数据的buffer。这个buffer可以用来处理url，header value等。

为啥要限制呢？如果写过解析一段字符串的代码就能明白，解析的时候要分配内存。对于一个字节流的解析，必须分配buffer来保存所有要存储的数据。而URL这种东西必须当作一个整体看待，无法一块一块处理，于是就处理一个请求时必须分配一整块足够大的内存。如果URL太长，而并发又很高，就容易挤爆服务器的内存；同时，超长URL的好处并不多，我也只有处理老系统的URL时因为不敢碰原来的逻辑，又得追加更多数据，才会使用超长URL。


# 8. ajax、 axios库
## 1. ajax
* 创建XMLHttpRequest类型的对象
* 准备发送，打开与网址之间的连接
* 执行发送动作
* 指定xhr状态变化事件处理函数
~~~
// 1.创建一个 XMLHttpRequest 类型的对象  --- 相当于打开了一个浏览器
var xhr = new XMLHttpRequest();
// 2.打开一个与网址之间的连接  --- 相当于在地址栏输入网址
xhr.open("GET","https://jsonplaceholder.typicode.com/users");
// 3.通过连接发送一次请求 --- 相当于点击回车或者超链接
xhr.send(null);
// 4.指定 xhr 状态变化事件处理函数   --- 相当于处理网页呈现后的操作
xhr.onreadystatechange = function () {
  // 通过判断 xhr 的 readyState ，确定此次请求是否完成
  if (this.readyState === 4) {
    console.log(this.responseText)
  }
}
~~~
## 2. Axios API
* 可以通过向axios()传递相关配置来创建请求
* axios(config) config为对象格式的配置选项
* axios(url,config) config可选

**常用配置选项**
* url 用于请求服务器的URL
* method 创建请求时使用的方法
* baseURL 传递相对URL前缀，将自动加在url前面
* headers 即将被发送的自定义请求头
* params 即将与请求一起发送的URL参数
* data 作为请求主体被发送的数据
* timeout 请求超时的毫秒数
* responseType 表示服务器响应的数据类型，默认json

~~~
axios({
  url: "/posts",
  method: "get",
  baseURL: "http://localhost:3000",
  params: {
    id: 1
  }
}).then(function(res){
  console.log(res.data)
})
~~~



# 9. 前端安全XSS、CSRF
## 1. XSS
>跨网站指令码（英语：Cross-site scripting，通常简称为：XSS）XSS 攻击是指攻击者在网站上注入恶意的客户端代码，通过恶意脚本对客户端网页进行篡改，从而在用户浏览网页时，对用户浏览器进行控制或者获取用户隐私数据的一种攻击方式。

攻击者对客户端网页注入的恶意脚本一般包括 JavaScript，有时也会包含 HTML 和 Flash。有很多种方式进行 XSS 攻击，但它们的共同点为：将一些隐私数据像 cookie、session 发送给攻击者，将受害者重定向到一个由攻击者控制的网站，在受害者的机器上进行一些恶意操作。

XSS 分为三种：**反射型，存储型和 DOM-based**

### 1. 反射性
反射型 XSS 只是简单地把用户输入的数据 “反射” 给浏览器，这种攻击方式往往需要攻击者诱使用户点击一个恶意链接，或者提交一个表单，或者进入一个恶意网站时，注入脚本进入被攻击者的网站。

看一个示例。我先准备一个如下的静态页：
![](https://ttarea.com/post-images/1616308450110.png)
当用户点击恶意链接时，页面跳转到攻击者预先准备的页面，会发现在攻击者的页面执行了 js 脚本：
![](https://ttarea.com/post-images/1616308453096.png)
这样就产生了反射型 XSS 攻击。攻击者可以注入任意的恶意脚本进行攻击，可能注入恶作剧脚本，或者注入能获取用户隐私数据(如cookie)的脚本，这取决于攻击者的目的。

### 2. 存储型
存储型 XSS 会把用户输入的数据 “存储” 在服务器端，当浏览器请求数据时，脚本从服务器上传回并执行。这种 XSS 攻击具有很强的稳定性。

比较常见的一个场景是攻击者在社区或论坛上写下一篇包含恶意 JavaScript 代码的文章或评论，文章或评论发表后，所有访问该文章或评论的用户，都会在他们的浏览器中执行这段恶意的 JavaScript 代码。

当用户点击提交按钮将输入信息提交到服务端时，服务端通过 userInput 变量保存了输入内容。当用户通过 http://localhost:8001/${id} 访问时，服务端会返回与 id 对应的内容(本示例简化了处理)。如果用户输入了恶意脚本内容，则其他用户访问该内容时，恶意脚本就会在浏览器端执行：
![](https://ttarea.com/post-images/1616308560547.png)

### 3. 基于DOM
基于 DOM 的 XSS 攻击是指通过恶意脚本修改页面的 DOM 结构，是纯粹发生在客户端的攻击。

点击 Submit 按钮后，会在当前页面插入一个链接，其地址为用户的输入内容。如果用户在输入时构造了如下内容：
```
'' onclick=alert(/xss/)
```
用户提交之后，页面代码就变成了：
```
<a href onlick="alert(/xss/)">testLink</a>
```
此时，用户点击生成的链接，就会执行对应的脚本：
![](https://ttarea.com/post-images/1616308646010.png)


## 2. XSS攻击的防范
现在主流的浏览器内置了防范 XSS 的措施，例如 CSP。但对于开发者来说，也应该寻找可靠的解决方案来防止 XSS 攻击。
### 1. HttpOnly 防止劫取 Cookie
浏览器将禁止页面的Javascript 访问带有 HttpOnly 属性的Cookie。

上文有说到，攻击者可以通过注入恶意脚本获取用户的 Cookie 信息。通常 Cookie 中都包含了用户的登录凭证信息，攻击者在获取到 Cookie 之后，则可以发起 Cookie 劫持攻击。所以，严格来说，HttpOnly 并非阻止 XSS 攻击，而是能阻止 XSS 攻击后的 Cookie 劫持攻击。

### 2. 输入检查
不要相信用户的任何输入。 对于用户的任何输入要进行检查、过滤和转义。建立可信任的字符和 HTML 标签白名单，对于不在白名单之列的字符或者标签进行过滤或编码。

在 XSS 防御中，输入检查一般是检查用户输入的数据中是否包含 <，> 等特殊字符，如果存在，则对特殊字符进行过滤或编码，这种方式也称为 XSS Filter。

而在一些前端框架中，都会有一份 decodingMap， 用于对用户输入所包含的特殊字符或标签进行编码或过滤，如 <，>，script，防止 XSS 攻击：
```
// vuejs 中的 decodingMap
// 在 vuejs 中，如果输入带 script 标签的内容，会直接过滤掉
const decodingMap = {
  '&lt;': '<',
  '&gt;': '>',
  '&quot;': '"',
  '&amp;': '&',
  '
  ': '\n'
}
```

### 3. 输出检查
用户的输入会存在问题，服务端的输出也会存在问题。一般来说，除富文本的输出外，在变量输出到 HTML 页面时，可以使用编码或转义的方式来防御 XSS 攻击。例如利用 sanitize-html 对输出内容进行有规则的过滤之后再输出到页面中。


## 3. CSRF
>跨站请求伪造（英语：Cross-site request forgery），中译是跨站请求伪造，是一种劫持受信任用户向服务器发送非预期请求的攻击方式。

通常情况下，CSRF 攻击是攻击者借助受害者的 Cookie 骗取服务器的信任，可以在受害者毫不知情的情况下以受害者名义伪造请求发送给受攻击服务器，从而在并未授权的情况下执行在权限保护之下的操作。
![](https://ttarea.com/post-images/1615455801140.jpg)

### 1. 浏览器的 Cookie 策略
Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。Cookie 主要用于以下两个方面：
* 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）
* 个性化设置（如用户自定义设置、主题等）

而浏览器所持有的 Cookie 分为两种：
* Session Cookie(会话期 Cookie)：会话期 Cookie 是最简单的Cookie，它不需要指定过期时间（Expires）或者有效期（Max-Age），它仅在会话期内有效，浏览器关闭之后它会被自动删除。
* Permanent Cookie(持久性 Cookie)：与会话期 Cookie 不同的是，持久性 Cookie 可以指定一个特定的过期时间（Expires）或有效期（Max-Age）。
```
res.setHeader('Set-Cookie', ['mycookie=222', 'test=3333; expires=Sat, 21 Jul 2018 00:00:00 GMT;']);
```
上述代码创建了两个 Cookie：mycookie 和 test，前者属于会话期 Cookie，后者则属于持久性 Cookie。当我们去查看 Cookie 相关的属性时，不同的浏览器对会话期 Cookie 的 Expires 属性值会不一样：
![](https://ttarea.com/post-images/1616309731128.png)
每个 Cookie 都会有与之关联的域，这个域的范围一般通过 donmain 属性指定。如果 Cookie 的域和页面的域相同，那么我们称这个 Cookie 为第一方 Cookie（first-party cookie），如果 Cookie 的域和页面的域不同，则称之为第三方 Cookie（third-party cookie）。一个页面包含图片或存放在其他域上的资源（如图片）时，第一方的 Cookie 也只会发送给设置它们的服务器。

### 2. 通过 Cookie 进行 CSRF 攻击
假设有一个 bbs 站点：http://www.c.com，当登录后的用户发起如下 GET 请求时，会删除 ID 指定的帖子：
```
http://www.c.com:8002/content/delete/:id
```
如发起 http://www.c.com:8002/content/delete/87343 请求时，会删除 id 为 87343 的帖子。当用户登录之后，会设置如下 cookie：
```
res.setHeader('Set-Cookie', ['user=22333; expires=Sat, 21 Jul 2018 00:00:00 GMT;']);
```
![](https://ttarea.com/post-images/1616309827160.png)
user 对应的值是用户 ID。然后构造一个页面 A：

CSRF 攻击者准备的网站：
```
<p>CSRF 攻击者准备的网站：</p>
<img src="http://www.c.com:8002/content/delete/87343">
页面 A 使用了一个 img 标签，其地址指向了删除用户帖子的链接：
```
![](https://ttarea.com/post-images/1616309871152.png)
可以看到，当登录用户访问攻击者的网站时，会向 www.c.com 发起一个删除用户帖子的请求。此时若用户在切换到 www.c.com 的帖子页面刷新，会发现ID 为 87343 的帖子已经被删除。

由于 Cookie 中包含了用户的认证信息，当用户访问攻击者准备的攻击环境时，攻击者就可以对服务器发起 CSRF 攻击。在这个攻击过程中，攻击者借助受害者的 Cookie 骗取服务器的信任，但并不能拿到 Cookie，也看不到 Cookie 的内容。而对于服务器返回的结果，由于浏览器同源策略的限制，攻击者也无法进行解析。因此，攻击者无法从返回的结果中得到任何东西，他所能做的就是给服务器发送请求，以执行请求中所描述的命令，在服务器端直接改变数据的值，而非窃取服务器中的数据。

但若 CSRF 攻击的目标并不需要使用 Cookie，则也不必顾虑浏览器的 Cookie 策略了。

## 4. CSRF 攻击的防范
当前，对 CSRF 攻击的防范措施主要有如下几种方式。
### 1. 验证码
验证码被认为是对抗 CSRF 攻击最简洁而有效的防御方法。

从上述示例中可以看出，CSRF 攻击往往是在用户不知情的情况下构造了网络请求。而验证码会强制用户必须与应用进行交互，才能完成最终请求。因为通常情况下，验证码能够很好地遏制 CSRF 攻击。

但验证码并不是万能的，因为出于用户考虑，不能给网站所有的操作都加上验证码。因此，验证码只能作为防御 CSRF 的一种辅助手段，而不能作为最主要的解决方案。

### 2. Referer Check
根据 HTTP 协议，在 HTTP 头中有一个字段叫 Referer，它记录了该 HTTP 请求的来源地址。通过 Referer Check，可以检查请求是否来自合法的”源”。

比如，如果用户要删除自己的帖子，那么先要登录 www.c.com，然后找到对应的页面，发起删除帖子的请求。此时，Referer 的值是 http://www.c.com；当请求是从 www.a.com 发起时，Referer 的值是 http://www.a.com 了。因此，要防御 CSRF 攻击，只需要对于每一个删帖请求验证其 Referer 值，如果是以 www.c.com 开头的域名，则说明该请求是来自网站自己的请求，是合法的。如果 Referer 是其他网站的话，则有可能是 CSRF 攻击，可以拒绝该请求。

Referer Check 不仅能防范 CSRF 攻击，另一个应用场景是 “防止图片盗链”。

### 3. 添加 token 验证(token==令牌)
CSRF 攻击之所以能够成功，是因为攻击者可以完全伪造用户的请求，该请求中所有的用户验证信息都是存在于 Cookie 中，因此攻击者可以在不知道这些验证信息的情况下直接利用用户自己的 Cookie 来通过安全验证。要抵御 CSRF，关键在于在请求中放入攻击者所不能伪造的信息，并且该信息不存在于 Cookie 之中。可以在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有 token 或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。


# 10. Websocket
webSocket是一项可以让服务器将数据主动推送给客户端的技术。

## 1. Websocket简介
它的最大特点就是，服务器可以主动向客户端推送信息，客户端也可以主动向服务器发送信息，是真正的双向平等对话，属于服务器推送技术的一种。
![](https://ttarea.com/post-images/1617946374224.png)
**其他特点包括：**
1. 建立在 TCP 协议之上，服务器端的实现比较容易。
2. 与 HTTP 协议有着良好的兼容性。默认端口也是80和443，并且握手阶段采用 HTTP 协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器。
3. 数据格式比较轻量，性能开销小，通信高效。
4. 可以发送文本，也可以发送二进制数据。
5. 没有同源限制，客户端可以与任意服务器通信。
6. 协议标识符是`ws`（如果加密，则为`wss`），服务器网址就是 URL。
```
ws://example.com:80/some/path
```
![](https://ttarea.com/post-images/1617946965265.jpg)


## 2. Websocket客户端示例
```
var ws = new WebSocket("wss://echo.websocket.org");

ws.onopen = function(evt) { 
  console.log("Connection open ..."); 
  ws.send("Hello WebSockets!");
};

ws.onmessage = function(evt) {
  console.log( "Received Message: " + evt.data);
  ws.close();
};

ws.onclose = function(evt) {
  console.log("Connection closed.");
};      
```
## 3. websocket应用场景
1、社交订阅
2、多玩家游戏
3、协同编辑文档
4、数据流状态
5、多人聊天




# 11. 即时通信
## SSE
ajax和JSONP 都是 client-fetch的操作. 但是有时候, 我们更需要服务器主动给我们发信息. 比如，现在的APP应用，完全可以实现服务器发送, 然后Client再处理。而SSE就是帮助我们向webapp靠近

**SSE 全称就是 Server-Sent Events**，，中译为 `服务器推送`
他的技术并不是很难，和websocket不同，他依赖原生的HTTP，所以对于开发者来说更好理解。 
比如，在nodeJS， 只要我不执行res.end()，并且一定时间持续发送信息的话，那么该连接就会持续打开(keep-alive)
其实通俗来说，就是一个长连接。 所以，以前我们通常使用ajax，iframe长轮询来代替他。但是这样有个缺点就是，可操控性弱， 错误率高。 
所以，正对于这点W3C, 觉得需要在客户端另外指定一个机制–能够保证服务器推送, 实现连接的keep-alive，操作简单… 在这样背景下SSE诞生了

# 12. 模块化，commonJS，es6，cmd，amd
## 1. ES6 Moudle
这个是目前前端小伙伴接触的最多的，是浏览器和服务端通用的模块化解决方案，主要命令为：export和import
export用于导出本模块对外的接口，import用于导入某个模块的功能。
>1. 如果单独导出一个变量或方法则是往将要导出{}对象里面添加属性。
2.如果导出的是{}，则和已生成的导出{}对象合并。

然后说一下特例`export default`，这个是在导出对象里面加一个`default`属性，还有一点值得注意的是`export default`后面不能跟变量表达式。

## 2. CommonJS
`CommonJS`最主要的代表就是`Node.js`，主要命令：`module、exports、require`。其中有个令人疑惑的点是exports和module.exports，其实理解起来也很简单，就是在模块里面加了一句： `exports = module.exports = {};` exports和module.exports指向同一个内存区域，只要在exports加了属性，则module.exports会跟着变化，但是最终导出对外的接口是以module.exports为准，所以不推荐直接使用exports。

对于`CommonJS`规范来说，很重要的一点是`CommonJS`输出的是一个值拷贝，并且是运行时加载。

## 3. CommonJS和ES6 Module的区别
*  引用方式：CommonJS模块输出是值的拷贝，ES6 Module模块输出的值是引用
* 时机：CommonJS是运行时加载，ES6 Module是编译是输出
* 前者支持动态导入，也就是 require(${path}/xx.js)，后者目前不支持，但是已有提案
* 前者是同步导入，因为用于服务端，文件都在本地，同步导入即使卡住主线程影响也不大。而后者是异步导入，因为用于浏览器，需要下载文件，如果也采用同步导入会对渲染有很大影响
* 前者在导出时都是值拷贝，就算导出的值变了，导入的值也不会改变，所以如果想更新值，必须重新导入一次。但是后者采用实时绑定的方式，导入导出的值都指向同一个内存地址，所以导入值会跟随导出值变化
* 后者会编译成 require/exports 来执行的

## 4. AMD
`AMD`规范是采用异步方式，依赖前置必须一开始就写好，所有的依赖加载完成后才会执行回调函数里的内容，模块的加载不影响它后面语句的运行。 

这里异步指的是不堵塞浏览器其他任务（dom构建，css渲染等），而加载内部是同步的（加载完模块后立即执行回调）。

AMD也采用require命令加载模块，但是不同于CommonJS，它要求两个参数：
```
require([module], callback);
```

## CMD
CMD推崇`依赖就近，延迟执行`。可以把你的依赖写进代码的任意一行，如下：
~~~
define(factory)
~~~
factory为函数时，表示是模块的构造方法。执行该构造方法，可以得到模块向外提供的接口。factory 方法在执行时，默认会传入三个参数：require、exports 和 module.

# 13. 负载均衡
## 1. 负载均衡概念
是指单台服务器性能达到极限时通过服务器集群来横向增加系统的吞吐量和性能。
![](https://ttarea.com/post-images/1628733553835.jpeg)
## 2. 服务器负载均衡
服务器负载均衡就是我们平时说的负载均衡，是指在服务器上游做服务分发，常用的方式有一下几种：
*  **DNS域名解析负载均衡**：假设我们的域名指向了多个IP地址，当一个域名请求来时，DNS服务器机进行域名解析将域名转换为IP地址是，在1:N的映射转换中实现负载均衡。DNS服务器提供简单的负载均衡算法，但当其中某台服务器出现故障时，通知DNS服务器移除当前故障IP。
* **反向代理负载均衡**：反向代理只值对服务器的代理，代理服务器接受请求，通过负载均衡算法，将请求转发给后端服务器，后端服务返回给代理服务器然后代理服务器返回到客户端。反向代理服务器的优点是隔离后端服务器和客户端，使用双网卡屏蔽真实服务器网络，安全性更好，相比较于DNS域名解决负载均衡，反向代理在故障处理方面更灵活，支持负载均衡算法的横向扩展。目前使用非常广泛。当然反向代理也需要考虑很多问题，比如单点故障，集群部署等。
* **IP负载均衡**：我们都知道反向代理工作到HTTP层，本身开销相对大一些，对性能有一定影响，LVS-NAT是一种卫浴传输层的负载均衡，它通过修改接受的数据包目标地址的方式实现负载均衡。Linux2.6.x以后版本内置了IPVS，专注用于实现IP负载均衡，故而在Linux上IP负载均衡使用非常广泛。LVS-DR工作在数据链路层，比LVS-NAT更霸道的时候它直接修改数据包的MAC地址。LVS-TUN——基于IP隧道的请求转发机制，将调度器收到的IP数据包进行封装，转交给服务器，然后服务器返回数据，通过调度器实现负载均衡。这种方式支持跨网段调度。总结一下，LVS-DR和LVS-TUN都适合响应和请求不对称的Web服务器，如何从它们中做出选择，取决于你的网络部署需要，因为LVS-TUN可具有跨地域性，有类似这种需求的，就应该选择LVS-TUN。
 

 ## 3. 客户端负载均衡
 相比较服务器负载均衡而言，客户端负载均衡是一个非常小众的概念，但是面试在问道负载均衡相关知识的时候却会刻意了解候选人的知识广度。客户端负载均衡是在spring-cloud分布式框架组件Ribbon中定义的。我们在使用spring-cloud分布式框架时，同一个service大概率同时启动多个，当一个请求奔过来时，那么这多个service，Ribbon通过策略决定本次请求使用哪个service的方式就是客户端负载均衡。在spring-cloud分布式框架中客户端负载均衡对开发者是透明的，添加@LoadBalanced注解就可以了。客户端负载均衡和服务器负载均衡的核心差异在服务列表本身，客户端负载均衡服务列表在通过客户端维护，服务器负载均衡服务列表由中间服务单独维护。

通过对以上知识的理解，大家能够对负载均衡有的较为全面的认识，下来我再简单的和面试官聊一聊常见的负载均衡算法：
* 随机，通过随机选择服务进行执行，一般这种方式使用较少;
* 轮训，负载均衡默认实现方式，请求来之后排队处理;
* 加权轮训，通过对服务器性能的分型，给高配置，低负载的服务器分配更高的权重，均衡各个服务器的压力;
* 地址Hash，通过客户端请求的地址的HASH值取模映射进行服务器调度。
* 最小链接数;即使请求均衡了，压力不一定会均衡，最小连接数法就是根据服务器的情况，比如请求积压数等参数，将请求分配到当前压力最小的服务器上。

# 14. npm 与 yarn
## 1. npm的坑
“Yarn是由Facebook、Google、Exponent 和 Tilde 联合推出了一个新的 JS 包管理工具 ，正如官方文档中写的，Yarn 是为了弥补 npm 的一些缺陷而出现的。”这句话让我想起了使用npm时的坑了：
* `npm install`的时候巨慢。特别是新的项目拉下来要等半天，删除 node_modules，重新install的时候依旧如此。
* 同一个项目，安装的时候无法保持一致性。由于package.json文件中版本号的特点，下面三个版本号在安装的时候代表不同的含义。
```
"5.0.3",
"~5.0.3",
"^5.0.3"
```
“5.0.3”表示安装指定的5.0.3版本，“～5.0.3”表示安装5.0.X中最新的版本，“^5.0.3”表示安装5.X.X中最新的版本。这就麻烦了，常常会出现同一个项目，有的同事是OK的，有的同事会由于安装的版本不一致出现bug。
* 安装的时候，包会在同一时间下载和安装，中途某个时候，一个包抛出了一个错误，但是npm会继续下载和安装包。因为npm会把所有的日志输出到终端，有关错误包的错误信息就会在一大堆npm打印的警告中丢失掉，并且你甚至**永远不会注意到实际发生的错误**。

## 2. Yarn的优点
### 1. 速度快 
速度快主要来自以下`两个方面`：
1. **并行安装**：无论 npm 还是 Yarn 在执行包的安装时，都会执行一系列任务。npm 是按照队列执行每个 package，也就是说必须要等到当前 package 安装完成之后，才能继续后面的安装。而 Yarn 是同步执行所有任务，提高了性能。

2. **离线模式**：如果之前已经安装过一个软件包，用Yarn再次安装时之间从缓存中获取，就不用像npm那样再从网络下载了。

### 2. 安装版本统一
为了防止拉取到不同的版本，Yarn 有一个锁定文件 (lock file) 记录了被确切安装上的模块的版本号。每次只要新增了一个模块，Yarn 就会创建（或更新）yarn.lock 这个文件。这么做就保证了，每一次拉取同一个项目依赖时，使用的都是一样的模块版本。

### 3. 更简洁的输出
npm 的输出信息比较冗长。在执行 npm install <package> 的时候，命令行里会不断地打印出所有被安装上的依赖。相比之下，Yarn 简洁太多：默认情况下，结合了 emoji直观且直接地打印出必要的信息，也提供了一些命令供开发者查询额外的安装信息。

### 4. 多注册来源处理：
所有的依赖包，不管他被不同的库间接关联引用多少次，安装这个包时，只会从一个注册来源去装，要么是 npm 要么是 bower, 防止出现混乱不一致。

### 5. 更好的语义化：
yarn改变了一些npm命令的名称，比如 yarn add/remove，感觉上比 npm 原本的 install/uninstall 要更清晰。

## 3. npm的未来：npm5.0
有了yarn的压力之后，npm做了一些类似的改进。
1. 默认新增了类似yarn.lock的 package-lock.json；
2. git 依赖支持优化：这个特性在需要安装大量内部项目（例如在没有自建源的内网开发），或需要使用某些依赖的未发布版本时很有用。在这之前可能需要使用指定 commit_id 的方式来控制版本。
3. 文件依赖优化：在之前的版本，如果将本地目录作为依赖来安装，将会把文件目录作为副本拷贝到 node_modules 中。而在 npm5 中，将改为使用创建 symlinks 的方式来实现（使用本地 tarball 包除外），而不再执行文件拷贝。这将会提升安装速度。目前yarn还不支持。


# 15. npm -dev 输入后的执行过程
## 1. 启动过程 npm run dev
npm run XXX是执行配置在package.json中的脚本，比如：
```
"scripts": {
    "dev": "node build/dev-server.js",
    "start": "node build/dev-server.js",
    "build": "node build/build.js"
  },
```
这里就是执行了 node build/dev-server.js文件。

## 2. main.js和index.html
build/dev-server.js里var webpackConfig = require('./webpack.dev.conf') 调用了webpack.dev.conf配置文件。
```
var config = require('../config')
if (!process.env.NODE_ENV) {
  process.env.NODE_ENV = JSON.parse(config.dev.env.NODE_ENV)
}
 
var opn = require('opn')
var path = require('path')
var express = require('express')
var webpack = require('webpack')
var proxyMiddleware = require('http-proxy-middleware')
var webpackConfig = require('./webpack.dev.conf')
```
webpack.dev.conf文件通过merge引用了webpack.base.conf.js文件。
![](https://ttarea.com/post-images/1633593241226.png)
在webpack.base.conf.js文件中调用了./src/main.js
![](https://ttarea.com/post-images/1633593256700.png)
main.js用到了一个html元素#app。
```
import Vue from 'vue'
import App from './App'
import router from './router'
import Mint from 'mint-ui'
 
var jquery = require('jquery');
 
Vue.config.productionTip = false
 
/* eslint-disable no-new */
new Vue({
  el: '#app',
  router,
  template: '<App/>',
  components: { App }
})
```
再次回到webpack.dev.conf.js文件的结尾处。
```
 new HtmlWebpackPlugin({
      filename: 'index.html',
      template: 'index.html',
      inject: true
    }),
```
template指定了index.html作为输出文件的模板文件。

# 16. 输入npm install 后执行了什么操作
**npm是Node的模块管理工具**
正因为有了npm我们只要执行一行命令，就可以安装别人写好的模块
```
npm install
```

## 1. 从npm install说起
Npm install 命令用来安装模块到node_module目录中
在安装之前，npm install会先检查，node_module目录之中是不是已经存在指定的模块，如果存在，就不再进行安装，即使远程仓库已经有了新版本，也是如此
如果你希望，一个模块不管是否安装过都重新新安装一遍，可以用-f 或者—force参数
```
npm install <packageName> --force
```

## 2. 更新现有模块
如果想更新已安装的模块，可以使用npm-update命令，会先远程仓库更新到最新版本，如果本地版本不存在，或者远程仓库已经有最新版本就会安装。
```
npm update
```

## 3. 模块的安装进程
1. 发出npm install命令
2. Npm 向registry查询模块压缩包的网址
3. 下载压缩包，放在~/.npm目录
4. 解压压缩包到当前项目的node_modules目录

注意，一个模块安装后，本地其实保存了两份，一份是~/.npm下的压缩包，另一份是node_modules目录下解压后的代码。在npm install运行的时候，只会检查node_modules中的模块，而不会检查/.npm.也就是说，如果在/.npm中有压缩包但是node_modules中没有模块，npm install会从远程仓库再下载一次压缩包。

## 4. 执行npm install之后的细节
1. 执行工程自身的preinstall

2. 定义首层依赖模块
首先需要做的就是工程中的首层依赖，也就是dependencies和devDependencies属性中直接指定的模块。
工程本身是整颗依赖树的根节点，每个首层依赖模块都是根节点下面的一颗子树，npm会开启多进程从每个首层依赖模块开始逐步寻找更深层级的节点。

3. 获取模块
* 获取模块信息。在下载一个模块之前，首先要确定其版本，这是因为 package.json 中往往是 semantic version（semver，语义化版本）。此时如果版本描述文件（npm-shrinkwrap.json 或
package-lock.json）中有该模块信息直接拿即可，如果没有则从仓库获取。如 packaeg.json 中某个包的版本是 ^1.1.0，npm 就会去仓库中获取符合 1.x.x 形式的最新版本。
* 获取模块实体。上一步会获取到模块的压缩包地址（resolved字段），npm
会用此地址检查本地缓存，缓存中有就直接拿，如果没有则从仓库下载。
* 查找该模块依赖，如果有依赖则回到第1步，如果没有则停止。

4. 模块扁平化（dedupe）
上一步获取到的是一棵完整的依赖树，其中可能包含大量重复模块。比如 A 模块依赖于 loadsh，B 模块同样依赖于 lodash。在 npm3 以前会严格按照依赖树的结构进行安装，因此会造成模块冗余。

从 npm3 开始默认加入了一个 dedupe 的过程。它会遍历所有节点，逐个将模块放在根节点下面，也就是 node-modules 的第一层。当发现有重复模块时，则将其丢弃。

这里需要对重复模块进行一个定义，它指的是模块名相同且 semver 兼容。每个 semver 都对应一段版本允许范围，如果两个模块的版本允许范围存在交集，那么就可以得到一个兼容版本，而不必版本号完全一致，这可以使更多冗余模块在 dedupe 过程中被去掉。
